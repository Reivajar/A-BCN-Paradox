{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results processing and data viz\n",
    "From microsimulation experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import cm\n",
    "import matplotlib.colors as colors\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "pd.set_option('display.max_rows', 3000)\n",
    "\n",
    "#SETTING SUMO_HOME\n",
    "SUMO_HOME = r\"C:\\Program Files (x86)\\Eclipse\\Sumo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source results files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder_net01 = r\"net01/data/results/\"\n",
    "results_folder_net02 = r\"net02/data/results/\"\n",
    "results_folder_net03 = r\"net03/data/results/\"\n",
    "results_folder_net04 = r\"net04/data/results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of performance of each network \n",
    "## (optional)\n",
    "Some quick visualizations can be optionally created for checking how each network behaves with the increasing levels of traffic with the scaling factors. Then, the point of optimal functioning of the network can be identified by checking when these networks minimum average speed drops. It is an indicator of the saturation of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming summary files from xml to csv\n",
    "\n",
    "def transform_summary_xml_to_csv(results_folder):\n",
    "    if not os.path.exists(results_folder + r\"/csv\"):\n",
    "        os.makedirs(results_folder + r\"/csv\")\n",
    "\n",
    "    for file in os.listdir(results_folder):\n",
    "        if file.endswith(\"summary.xml\"):\n",
    "            input_xml_file = str(results_folder + file)\n",
    "            output_csv_file = str(results_folder + r\"/csv/\" + file[:-3] + \"csv\")\n",
    "            # bash command\n",
    "            !python \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\xml\\xml2csv.py\" \\\n",
    "            --output \"{output_csv_file}\" \\\n",
    "            \"{input_xml_file}\"\n",
    "            \n",
    "# Building new pandas dataframe based on summary data from the results summary csv files\n",
    "\n",
    "def create_pandas_df_summary(results_folder):\n",
    "    total_veh_ref = 315000\n",
    "\n",
    "    #new pandas dataframe\n",
    "    column_names = ['scale', 'loaded_veh', 'min_avg_speed', 'mean_avg_speed', 'max_avg_speed', 'max_veh_running']\n",
    "    df_summary = pd.DataFrame(columns = column_names)\n",
    "\n",
    "    for file in os.listdir(results_folder + \"/csv/\"):\n",
    "        if file.endswith(\"summary.csv\"):\n",
    "            output_csv_file = str(results_folder + r\"/csv/\" + file)\n",
    "            df = pd.read_csv(output_csv_file, sep=\";\")\n",
    "            df.index = pd.to_datetime(df.index, unit='s')\n",
    "            df_5min = df.resample('5T').mean()\n",
    "            scale =  float(output_csv_file.split('_')[-2])\n",
    "            loaded_veh = scale*total_veh_ref\n",
    "            min_avg_speed = df_5min['step_meanSpeed'].min()\n",
    "            mean_avg_speed = df_5min['step_meanSpeed'].mean()\n",
    "            max_avg_speed = df_5min['step_meanSpeed'].max()\n",
    "            max_veh_running = df_5min['step_running'].max()\n",
    "\n",
    "            df_summary.loc[len(df_summary.index)] = [scale, \n",
    "                                                     loaded_veh, \n",
    "                                                     min_avg_speed, \n",
    "                                                     mean_avg_speed, \n",
    "                                                     max_avg_speed, \n",
    "                                                     max_veh_running]\n",
    "    return df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_summary_xml_to_csv(results_folder_compar002)\n",
    "transform_summary_xml_to_csv(results_folder_compar052)\n",
    "transform_summary_xml_to_csv(results_folder_compar032)\n",
    "transform_summary_xml_to_csv(results_folder_compar102)\n",
    "\n",
    "df_compar002 = create_pandas_df_summary(results_folder_compar002)\n",
    "df_compar032 = create_pandas_df_summary(results_folder_compar032)\n",
    "df_compar052 = create_pandas_df_summary(results_folder_compar052)\n",
    "df_compar102 = create_pandas_df_summary(results_folder_compar102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_list_01 = cm.jet(np.linspace(0,1,10))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "fig.suptitle('Comparison', fontsize=16)\n",
    "\n",
    "list = [df_compar002, df_compar032, df_compar052, df_compar102]\n",
    "names = ['net01', 'net02', 'net03', 'net04']\n",
    "line_colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red']\n",
    "shade_color = [(0,0.6,1,0.25), (1,0.6,0,0.25), (0,1,0.45,0.25), (1,0,0,0.25)]\n",
    "for i in range(len(list)):\n",
    "    df = list[i]\n",
    "    ax.plot(df['scale'], df['mean_avg_speed'], color=line_colors[i], lw=2, linestyle='dashed', label=names[i])\n",
    "    down = ax.plot(df['scale'], df['min_avg_speed'], color=line_colors[i], lw=1)\n",
    "    top = ax.plot(df['scale'], df['max_avg_speed'], color=line_colors[i], lw=1)\n",
    "    ax.fill_between(df['scale'], df['max_avg_speed'], df['min_avg_speed'], facecolor=shade_color[i])\n",
    "\n",
    "plt.ylabel('Mean speed')\n",
    "plt.xlabel('Total veh loaded')\n",
    "ax.legend(loc=\"upper left\")\n",
    "plt.xticks(np.arange(0, 2, step=0.05))\n",
    "ax.xaxis.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = \"0.10\"\n",
    "experiments = ['net01', 'net02', 'net03', 'net04']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=4, ncols=1, figsize=(20,15), sharex=True, \n",
    "                       gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "fig.suptitle('Loading of vehicles comparison at scale {}'.format(scale), fontsize=16)\n",
    "\n",
    "for exp in experiments:\n",
    "    output_csv_file = r\"{}\\data\\results\\csv\\scale_{}_summary.csv\".format(exp, scale)\n",
    "    df = pd.read_csv(output_csv_file, sep=\";\")\n",
    "    df.index = pd.to_datetime(df.index, unit='s')\n",
    "    ax[0].plot(df.index, df['step_running'].rolling(window=300).mean(), label=\"{} at scale {}\".format(exp, scale))\n",
    "    ax[1].plot(df.index, df['step_ended'].rolling(window=300).mean(), label=\"{} at scale {}\".format(exp, scale))\n",
    "    ax[2].plot(df.index, df['step_meanSpeed'].rolling(window=300).mean(), label=\"{} at scale {}\".format(exp, scale))\n",
    "    ax[3].plot(df.index, df['step_meanTravelTime'].rolling(window=300).mean(), label=\"{} at scale {}\".format(exp, scale))\n",
    "    \n",
    "ax[0].xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "ax[0].set_ylabel('Veh running in simulation')\n",
    "ax[1].set_ylabel('Veh loaded into the simulation')\n",
    "ax[2].set_ylabel('Mean speed m/s')\n",
    "ax[3].set_ylabel('Mean travel time (s)')\n",
    "ax[0].legend(loc=\"upper left\")\n",
    "ax[0].set_xlim(df.index.min(),df.index.max())\n",
    "ax[0].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "fig.autofmt_xdate(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic fundamental diagram\n",
    "Network metrics are needed for normalizing the results accross the different networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total length of lanes for the different networks\n",
    "net_length_002 = 53920\n",
    "\n",
    "net_length_032_x2lanes = 2456.6 + 2516.6 + 2943.12 + 929.84 + 955.44 + 506.52 + 5373.72 + 4629.2 + 2854.32 + 1038.64 + 1503.96 + 507.32 + 504.52\n",
    "net_length_032_x1lanes = 504.32 + 979.04 + 475.72 + 490.52 + 754.98 + 965.24 + 1904.88 + 1851.68 + 978.04 + 964.24\n",
    "net_length_032 = net_length_032_x2lanes + net_length_032_x1lanes\n",
    "\n",
    "net_length_052_x2lanes = 21186.08\n",
    "net_length_052_x1lanes = 7263.8 + 5811.04\n",
    "net_length_052 = net_length_052_x2lanes + net_length_052_x1lanes\n",
    "\n",
    "net_length_102 = 58918.52\n",
    "\n",
    "\n",
    "# Num of edges per network\n",
    "num_edges_compar002 = 220\n",
    "num_edges_compar032 = 192\n",
    "num_edges_compar052 = 196\n",
    "num_edges_compar102 = 242"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for transforming the original XML files that SUMO creates as results of the simulation into CSV files and then dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for transforming XLM output files into \n",
    "\n",
    "def transform_aadt_output_xml_to_csv(results_folder):\n",
    "    if not os.path.exists(results_folder + r\"/csv\"):\n",
    "        os.makedirs(results_folder + r\"/csv\")\n",
    "\n",
    "    for file in os.listdir(results_folder):\n",
    "        if file.endswith(\"aadt_output_freq60s.xml\"):\n",
    "            input_xml_file = str(results_folder + file)\n",
    "            output_csv_file = str(results_folder + r\"/csv/\" + file[:-3] + \"csv\")\n",
    "            # bash command\n",
    "            !python \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\xml\\xml2csv.py\" \\\n",
    "            --output \"{output_csv_file}\" \\\n",
    "            \"{input_xml_file}\"\n",
    "\n",
    "# Building new pandas dataframe based on summary data from the results summary csv files\n",
    "\n",
    "def create_df_for_traffic_fundamental_diagram(results_folder, net_length, num_edges):\n",
    "    \n",
    "    column_names = ['experiment', 'scale', 'lanes_length_m', 'flow', 'density', 'freq', 'edge_entered', 'edge_departed', 'edge_sampledSeconds']\n",
    "    df_output = pd.DataFrame(columns = column_names)\n",
    "    #iterate through the folder\n",
    "    for file in os.listdir(results_folder + \"/csv/\"):\n",
    "        if file.endswith(\"aadt_output_freq60s.csv\"):\n",
    "            output_csv_file =  str(results_folder + r\"/csv/\" + file)\n",
    "            scale = float(output_csv_file.split('_')[-5])\n",
    "            experiment = results_folder.split('/')[0]\n",
    "            freq = 60\n",
    "            #transform to pandas df\n",
    "            df = pd.read_csv(output_csv_file, sep=\";\")\n",
    "            #groupby\n",
    "            df_g = df.groupby('interval_begin')[['edge_entered', 'edge_departed', 'edge_sampledSeconds']].apply(sum)\n",
    "            #create variables of fundamental traffic diagram (#some refs: https://www.eclipse.org/lists/sumo-user/msg06970.html)\n",
    "            df_g['scale'] = scale\n",
    "            df_g['lanes_length_m'] = net_length\n",
    "            df_g['flow'] = (((df_g.edge_entered + df_g.edge_departed)/freq)*3600)/num_edges #maybe freq here no TODO!!!!!\n",
    "            df_g['density'] = (df_g.edge_sampledSeconds/freq)/(net_length/1000)\n",
    "            df_g['experiment'] = experiment\n",
    "            df_g['freq'] = freq\n",
    "            #merge\n",
    "            frames = [df_output, df_g]\n",
    "            df_output = pd.concat(frames)\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for smoothing the data and obtaining the critical points of the fundamental diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import pchip\n",
    "import statsmodels.api as sm\n",
    "from operator import itemgetter\n",
    "\n",
    "# COMBINING PCHIP AND LOWESS\n",
    "def fit(x,y):\n",
    "    \n",
    "    pch = pchip(x, y)\n",
    "    \n",
    "    xx = np.linspace(x[0], x[-1], 1000)\n",
    "    yy = pch(xx)\n",
    "    \n",
    "    lowess = sm.nonparametric.lowess(yy, xx, frac=0.2)\n",
    "    \n",
    "    x_lowess = lowess[:, 0]\n",
    "    y_lowess = lowess[:, 1]\n",
    "    return [x_lowess, y_lowess]\n",
    "\n",
    "\n",
    "def estimate_critical_metrics(exp_df):\n",
    "    \n",
    "    exp_df_mod = exp_df.groupby('density').mean()\n",
    "    exp_df_mod = exp_df_mod.sort_index()\n",
    "    \n",
    "    x = exp_df_mod.index\n",
    "    y = exp_df_mod.flow\n",
    "\n",
    "    [x2, y2] = fit(x, y)\n",
    "    \n",
    "    max_flow = max(y2)\n",
    "    density_at_max_flow = x2[y2.argmax()]\n",
    "    estimated_optimal_speed = (max_flow/density_at_max_flow) \n",
    "    return (max_flow, density_at_max_flow, estimated_optimal_speed, x2, y2)\n",
    "\n",
    "def create_df_critical_metrics():\n",
    "    \n",
    "    column_names = ['experiment', 'lanes_length_m', 'max_flow', 'density_At_max_flow', 'optim_speed']\n",
    "    df_compa = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "    for df_exp in [df_tdf_002, df_tdf_032, df_tdf_052, df_tdf_102]:\n",
    "        critical_metrics = estimate_critical_metrics(df_exp)\n",
    "        df_compa.loc[len(df_compa.index)] = [df_exp.experiment.iloc[0], \n",
    "                                             df_exp.lanes_length_m.iloc[0], \n",
    "                                             critical_metrics[0], \n",
    "                                             critical_metrics[1], \n",
    "                                             critical_metrics[2]]\n",
    "    \n",
    "    return df_compa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_aadt_output_xml_to_csv(results_folder_compar002)\n",
    "transform_aadt_output_xml_to_csv(results_folder_compar032)\n",
    "transform_aadt_output_xml_to_csv(results_folder_compar052)\n",
    "transform_aadt_output_xml_to_csv(results_folder_compar102)\n",
    "\n",
    "df_tdf_002 = create_df_for_traffic_fundamental_diagram(results_folder_compar002, net_length_002, num_edges_compar002)\n",
    "df_tdf_032 = create_df_for_traffic_fundamental_diagram(results_folder_compar032, net_length_032, num_edges_compar032)\n",
    "df_tdf_052 = create_df_for_traffic_fundamental_diagram(results_folder_compar052, net_length_052, num_edges_compar052)\n",
    "df_tdf_102 = create_df_for_traffic_fundamental_diagram(results_folder_compar102, net_length_102, num_edges_compar102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critical_metrics = create_df_critical_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz\n",
    "Basic fundamental diagrams comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,15), sharex=True, \n",
    "                       gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "\n",
    "fig.suptitle('Fundamental diagram of traffic flow', fontsize=16, y=0.9)\n",
    "col = [\"#648FFF\", \"#DC267F\", \"#FE0000\", \"#FFB000\"]\n",
    "# col = [\"#9b7000\", \"#23d980\", \"#01ffff\", \"#004fff\"] #INVERT\n",
    "\n",
    "ax.scatter(df_tdf_002.density, df_tdf_002['flow'], color=col[0], s=50, alpha=0.05, label=\"compar_002 (existing situation)\")\n",
    "ax.scatter(df_tdf_032.density, df_tdf_032['flow'], color=col[1], s=50, alpha=0.05, label=\"compar_032 (Cerda's original grid)\")\n",
    "ax.scatter(df_tdf_052.density, df_tdf_052['flow'], color=col[2], s=50, alpha=0.05, label=\"compar_052 (Superblocks grid)\")\n",
    "ax.scatter(df_tdf_102.density, df_tdf_102['flow'], color=col[3], s=50, alpha=0.05, label=\"compar_102 (existing situation with diagonal avenue)\")\n",
    "\n",
    "ax.plot(estimate_critical_metrics(df_tdf_002)[3], estimate_critical_metrics(df_tdf_002)[4], color=col[0], label=\"compar_002 (existing situation)\")\n",
    "ax.plot(estimate_critical_metrics(df_tdf_032)[3], estimate_critical_metrics(df_tdf_032)[4], color=col[1], label=\"compar_032 (Cerda's original grid)\")\n",
    "ax.plot(estimate_critical_metrics(df_tdf_052)[3], estimate_critical_metrics(df_tdf_052)[4], color=col[2], label=\"compar_052 (Superblocks grid)\")\n",
    "ax.plot(estimate_critical_metrics(df_tdf_102)[3], estimate_critical_metrics(df_tdf_102)[4], color=col[3], label=\"compar_102 (existing situation with diagonal avenue)\")\n",
    "\n",
    "ax.set_ylabel('Flow (veh/h) - per edge of the network')\n",
    "ax.set_xlabel('Density (veh/km)')\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_xlim(-5,140)\n",
    "ax.set_ylim(-50,1400)\n",
    "ax.axhline(y=0, xmin=-0.05, xmax=0.1, color=(0.25, 0.25, 0.25, 0.25))\n",
    "ax.axvline(x=0, ymin=-0.05, ymax=0.1, color=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "fig.savefig(\"charts/MFD01_compar_002-032-052-102.png\",\n",
    "        orientation='portrait',\n",
    "        transparent=True,\n",
    "        frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamental diagram comparison with scale values for each simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(25,15), sharex=True, \n",
    "                       gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "\n",
    "color_002 = cm.get_cmap('coolwarm')\n",
    "\n",
    "fig.suptitle('Fundamental diagram of traffic flow with scale', fontsize=16, y=0.9)\n",
    "\n",
    "ax.scatter(df_tdf_002.density, df_tdf_002['flow'], marker='o', s=100, alpha=0.1, color=color_002(df_tdf_002.scale/2), label=\"compar_002 (existing situation)\")\n",
    "ax.scatter(df_tdf_032.density, df_tdf_032['flow'], marker='+', s=100, alpha=0.25, color=color_002(df_tdf_032.scale/2), label=\"compar_032 (Cerda's original grid)\")\n",
    "ax.scatter(df_tdf_052.density, df_tdf_052['flow'], marker='^', s=100, alpha=0.25, color=color_002(df_tdf_052.scale/2), label=\"compar_052 (Superblocks grid)\")\n",
    "ax.scatter(df_tdf_102.density, df_tdf_102['flow'], marker='x', s=100, alpha=0.1, color=color_002(df_tdf_102.scale/2), label=\"compar_102 (existing situation with diagonal avenue)\")\n",
    "\n",
    "ax.plot(estimate_critical_metrics(df_tdf_002)[3], estimate_critical_metrics(df_tdf_002)[4], color=col[0])\n",
    "ax.plot(estimate_critical_metrics(df_tdf_032)[3], estimate_critical_metrics(df_tdf_032)[4], color=col[1])\n",
    "ax.plot(estimate_critical_metrics(df_tdf_052)[3], estimate_critical_metrics(df_tdf_052)[4], color=col[2])\n",
    "ax.plot(estimate_critical_metrics(df_tdf_102)[3], estimate_critical_metrics(df_tdf_102)[4], color=col[3])\n",
    "\n",
    "ax.set_ylabel('Flow (veh/s)')\n",
    "ax.set_xlabel('Density (veh/km)')\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.set_xlim(-5,140)\n",
    "ax.set_ylim(-50,1400)\n",
    "ax.axhline(y=0, xmin=-0.05, xmax=0.1, color=(0.25, 0.25, 0.25, 0.25))\n",
    "ax.axvline(x=0, ymin=-0.05, ymax=0.1, color=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "cNorm  = colors.Normalize(vmin=0, vmax=2)\n",
    "scalarMap = cm.ScalarMappable(norm=cNorm, cmap=color_002)\n",
    "scalarMap.set_array([])\n",
    "cbar = fig.colorbar(scalarMap,ax=ax, aspect=40)\n",
    "cbar.set_label('scale of demand load (1 = current adjusted demand)', rotation=270,  labelpad=-70)\n",
    "\n",
    "fig.savefig(\"charts/MFD02_compar_002-032-052-102.png\", dpi=None, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=True, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create edge-based visualizations for AADT levels\n",
    "* Static hourly snapshots for each network scenario at its optimal level of service (depending on the optimal scale or amount of allocated traffic).\n",
    "* Animation for each network scenario at its optimal level of service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "experiments = ['net01', 'net02', 'net03', 'net04']\n",
    "net_files = ['grid01-bcn_06.net.xml', 'grid01-bcn_10.net.xml', 'grid01-bcn_50.net.xml', 'grid01-bcn_100.net.xml']\n",
    "# dump_files = ['scale_1.00_edgedata_aadt_output.xml', 'scale_0.35_edgedata_aadt_output.xml',\n",
    "#              'scale_0.15_edgedata_aadt_output.xml', 'scale_0.40_edgedata_aadt_output.xml']\n",
    "dump_files_seq = ['scale_1.00_edgedata_aadt_output_freq60s.xml', 'scale_0.35_edgedata_aadt_output_freq60s.xml',\n",
    "             'scale_0.15_edgedata_aadt_output_freq60s.xml', 'scale_0.35_edgedata_aadt_output_freq60s.xml']\n",
    "\n",
    "for i in range(len(experiments)):\n",
    "    experiment = experiments[i]\n",
    "    net = net_files[i]\n",
    "    results_folder = r\"results\"\n",
    "    output_folder_anim = r\"imgs\\anim\"\n",
    "    output_folder_static = r\"imgs\\static\"\n",
    "    \n",
    "    if not os.path.exists(r\"{}\\data\\{}\\{}\".format(experiment, results_folder, output_folder_anim)):\n",
    "        os.makedirs(r\"{}\\data\\{}\\{}\".format(experiment, results_folder, output_folder_anim))\n",
    "    if not os.path.exists(r\"{}\\data\\{}\\{}\".format(experiment, results_folder, output_folder_static)):\n",
    "        os.makedirs(r\"{}\\data\\{}\\{}\".format(experiment, results_folder, output_folder_static))\n",
    "\n",
    "    #STATIC IMAGE AS SUMMARY\n",
    "    # iterate through the files\n",
    "    for file in os.listdir(r\"{}\\data\\{}\".format(experiment, results_folder)):\n",
    "        if file.endswith(\"aadt_output.xml\"):\n",
    "            dump = file\n",
    "    \n",
    "            NET_FILE = r\"{}\\data\\{}\".format(experiment, net)\n",
    "            DUMP_FILE = r\"{}\\data\\{}\\{}\".format(experiment, results_folder, dump) #the results folder changes depending on the simulation framework run (MESO vs SUMO)\n",
    "            OUTPUT_FILE_STATIC = r\"{}\\data\\{}\\{}\\{}.png\".format(experiment, results_folder, output_folder_static, dump)\n",
    "\n",
    "            #static\n",
    "            !python \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\visualization\\plot_net_dump.py\" -v \\\n",
    "            -n \"{NET_FILE}\" \\\n",
    "            -i \"{DUMP_FILE}\",\"{DUMP_FILE}\" \\\n",
    "            --measures sampledSeconds,sampledSeconds \\\n",
    "            --xticks 0 --yticks 0 \\\n",
    "            --default-color #ffffff00 --default-width 3 \\\n",
    "            --max-width 5 --min-width .1  \\\n",
    "            --colormap #0:#577590,.25:#90be6d,.5:#f9c74f,.75:#f8961e,1:#f94144 \\\n",
    "            -o \"{OUTPUT_FILE_STATIC}\"\n",
    "    \n",
    "    #ANIMATION\n",
    "    # creating png frames\n",
    "    dump_seq = dump_files_seq[i] \n",
    "    NET_FILE = r\"{}\\data\\{}\".format(experiment, net)\n",
    "    DUMP_FILE_SEQ = r\"{}\\data\\{}\\{}\".format(experiment, results_folder, dump_seq)\n",
    "    OUTPUT_FILE_ANIM = r\"{}\\data\\{}\\{}\\{}_%05d.png\".format(experiment, results_folder, output_folder_anim, dump_seq)\n",
    "    \n",
    "    !python \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\visualization\\mpl_dump_onNet2.py\" -v \\\n",
    "    -n \"{NET_FILE}\" \\\n",
    "    -d \"{DUMP_FILE_SEQ}\" \\\n",
    "    --value sampledSeconds,sampledSeconds \\\n",
    "    --color-map 0:#577590,.25:#90be6d,.5:#f9c74f,.75:#f8961e,1:#f94144 \\\n",
    "    --default-color #ffffff00 \\\n",
    "    --size 6,6 \\\n",
    "    -o \"{OUTPUT_FILE_ANIM}\"\n",
    "    \n",
    "    #create gif\n",
    "    images = []\n",
    "    anim_folder = r\"{}\\data\\{}\\{}\".format(experiment, results_folder, output_folder_anim)\n",
    "    output_gif_file = r\"{}\\data\\{}\\{}\\MOVIE_{}.gif\".format(experiment, results_folder, output_folder_anim, dump_seq)\n",
    "    for file in os.listdir(anim_folder):\n",
    "        if file.endswith(\".png\"):\n",
    "            filename = r\"{}\\{}\".format(anim_folder, file)\n",
    "            images.append(imageio.imread(filename))\n",
    "    print(\"SAVING GIF OF EXPERIMENT {} IN {}\".format(experiment,output_gif_file))\n",
    "    imageio.mimsave(output_gif_file, images, format='GIF', fps=60)\n",
    "    print('OPTIMIZING')\n",
    "    print(output_gif_file)\n",
    "    \n",
    "    OPTIMIZED_GIF = \"{}_{}\".format(output_gif_file[:-4], \"OPT.gif\")\n",
    "    !C:/gifsicle/gifsicle.exe \\\n",
    "    -O \"{output_gif_file}\" \\\n",
    "    -o \"{OPTIMIZED_GIF}\" \\\n",
    "    --colors 256"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
